<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Toward Advancing License Plate Super-Resolution in Real-World Scenarios: A Dataset and Benchmark</title>
    <style>
        .table {
            justify-content: center;
            margin: 0 auto;
            display: flex;
        }

        .table td {
            text-align: center;
            font-size: 19px; /* Fixed font size */
            padding: 5px 10px; /* Reduced padding for closer alignment */
        }

        .title {
            font-family: Arial, sans-serif;
            font-size: 38px;
            text-align: center;
            margin: auto;
            max-width: 800px; /* Reduced max width */
        }

        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #ffffff; /* Set background color to white */
        }

        /* Centered container for image and caption */
        figure {
            margin: 20px auto; /* Center the figure */
            text-align: center; /* Center text in the figure */
            max-width: 800px; /* Ensure the figure doesn't exceed this width */
        }

        img {
            max-width: 100%; /* Image takes full width of the figure */
            height: auto; /* Maintain aspect ratio */
            display: block; /* Treat image as block */
            margin: 0 auto; /* Center the image */
        }

        figcaption {
            margin-top: 10px;
            font-size: 14px; /* Caption font size */
            color: #555; /* Caption color */
            text-align: justify; /* Justify text */
        }

        hr {
            border: 0; /* Remove default border */
            height: 1px; /* Height of the line */
            background: #000000; /* Color of the line */
            margin: 20px auto; /* Center the line */
            max-width: 80% /* Adjust width of the line */
        }
	    
	sup {
            font-size: 10px;
        }

	a {
	    text-decoration: none;
	    color: #0073e6;
	}
	    
	h2 {
    	    border-top: 1px solid #000;
    	    text-align: center; /* Align text to the center */
    	    max-width: 790px; /* Match the width of the abstract */
     	    margin: 20px auto; /* Center the heading */
    	    padding-top: 10px; /* Optional: add some padding above the text */
	}
	
        .abstract, .paper {
            margin: 20px auto; /* Center and space out the section */
            padding: 15px; /* Padding around the section */
            border: 1px solid #ccc; /* Optional border around the section */
            border-radius: 5px; /* Rounded corners */
            max-width: 800px; /* Set a narrower max width for the section */
            background-color: #f9f9f9; /* Light background color */
            text-align: justify; /* Align text to the left */
        }
    </style>
</head>

<body>
<center>
<span class="title">Toward Advancing License Plate Super-Resolution <br> in Real-World Scenarios: A Dataset and Benchmark</span>
</center>
<table class="table">
    <tr>
        <td><span><a href="https://www.inf.ufpr.br/vwnascimento/" target="_blank">Valfride Nascimento</a><sup>1</sup></span></td>
	<td><span><a href="https://www.inf.ufpr.br/gelima/" target="_blank">Gabriel E. Lima</a><sup>1</sup></span></td>
	<td><span><a href="https://research.aston.ac.uk/en/persons/rafael-oliveira-ribeiro" target="_blank">Rafael O. Ribeiro</a><sup>2</sup></span></td>
	<td><span><a href="http://william.dcc.ufmg.br/">William Robson Schwartz</a><sup>3</sup></span></td>
        <td><span><a href="https://raysonlaroca.github.io/" target="_blank">Rayson Laroca</a><sup>1,4</sup></span></td>        
        <td><span><a href="https://web.inf.ufpr.br/menotti/" target="_blank">David Menotti</a><sup>1</sup></span></td>
    </tr>
</table>

<!-- Single line for the Federal University -->
<table class="table">
    <tr>
        <td colspan="4"><span style="display: inline-block; width: 100%;"><sup>1</sup>Federal University of Paraná</span></td>
    </tr>
    <tr>
        <td colspan="4"><span style="display: inline-block; width: 100%;"><sup>2</sup>Brazilian Federal Police</span></td>
    </tr>
    <tr>
        <td colspan="4"><span style="display: inline-block; width: 100%;"><sup>3</sup>Federal University of Minas Gerais </span></td>
    </tr>
    <tr>
        <td colspan="4"><span style="display: inline-block; width: 100%;"><sup>4</sup>Pontifical Catholic University of Paraná</span></td>
    </tr>
</table>

<!-- Figure Section -->
<figure>
    <img src="carssrplates1.png" alt="Description of the image">
    <figcaption>
    Examples of tracks from the UFPR-SR-Plates dataset. Each track comprises five consecutive LR images and five consecutive HR images of the same LP, captured under varying conditions. Each row shows a single track, with the LR images displayed on the left and the corresponding HR images on the right. We remark that even what we consider ‘HR’ in the context of this work is of lower quality than the datasets typically used in LPR research.
    </figure>



<!-- Abstract Section -->
<h2>Abstract</h2>
<div class="abstract">
    <p>Recent advancements in super-resolution for License Plate Recognition (LPR) have sought to address challenges posed by low-resolution (LR) and degraded images in surveillance, traffic monitoring, and forensic applications. However, existing studies have relied on private datasets and simplistic degradation models. To address this gap, we introduce UFPR-SR-Plates, a novel dataset containing 10,000 tracks with 100,000 paired low and high-resolution license plate images captured under real-world conditions. We establish a benchmark using multiple sequential LR and high-resolution (HR) images per vehicle – five of each – and two state-of-the-art models for super-resolution of license plates. We also investigate three fusion strategies to evaluate how combining predictions from a leading Optical Character Recognition (OCR) model for multiple super-resolved license plates enhances overall performance. Our findings demonstrate that super-resolution significantly boosts LPR performance, with further improvements observed when applying majority vote-based fusion techniques. Specifically, the Layout-Aware and Character-Driven Network (LCDNet) model combined with the Majority Vote by Character Position (MVCP) strategy led to the highest recognition rates, increasing from 1.7% with low-resolution images to 31.1% with super-resolution, and up to 44.7% when combining OCR outputs from five super-resolved images. These findings underscore the critical role of super-resolution and temporal information in enhancing LPR accuracy under real-world, adverse conditions. The proposed dataset is publicly available to support further research.</p>
</div>

	

<!-- Paper Section -->
<h2><center>Paper</center></h2>
<div class="paper">
    <p><strong>Authors:</strong> Valfride Nascimento, Gabriel E. Lima, Rafael O. Ribeiro, William Robson Schwartz, Rayson Laroca, David Menotti</p>
    <p><strong>Title:</strong> Toward Advancing License Plate Super-Resolution in Real-World Scenarios: A Dataset and Benchmark</p>
    <!--<p><strong>Conference:</strong> Iberoamerican Congress on Pattern Recognition (CIARP), pp. 60-75, Nov 2023.</p>-->
    <p><strong>Summary:</strong></p>
    <p>In summary, the main contributions of this work are:</p>
    <ul>
	<li>A publicly available dataset containing 100,000 images, divided into 10,000 tracks, with each track containing five LR images and five HR images of the same LP. To enhance variability, 5,000 tracks were collected at a resolution of 1280 × 960 pixels, while the remaining 5,000 tracks were captured at 1920 × 1080 pixels. The dataset is evenly distributed between Mercosur and Brazilian LPs, making it the largest dataset in terms of the number of LPs for both layouts;</li>
	<!-- <li>A publicly available dataset containing 100,000 images, divided into 10,000 tracks, with each track containing five LR images and five HR images of the same LP. To enhance variability, 5,000 tracks were collected at a resolution of 1280x920 pixels, while the remaining 5,000 tracks were captured at 1920x1080 pixels. The dataset is evenly distributed between Mercosur and Brazilian LPs, making it the largest dataset in terms of the number of LPs for both layouts</li> -->
        <!-- <li>We conducted benchmark experiments on the proposed dataset using two state-of-the-art models for super-resolving LPs, namely the PLNET and LCDNet networks proposed in [Nascimento et al., 2024<a href="https://raysonlaroca.github.io/papers/nascimento2023super.pdf" target="_blank">a</a>, <a href="https://raysonlaroca.github.io/papers/nascimento2024enhancing.pdf" target="_blank">b</a>]. For each track, we generated five super-resolved images from the LR images and compared the recognition results obtained by the leading Optical Character Recognition (OCR) model, GP_LPR <a href="https://github.com/MMM2024/GP_LPR" target="_blank">[Liu et al., 2024b]</a>. The super-resolution process significantly boosted recognition accuracy, increasing from 1.7% to 31.1%. To further enhance LPR performance, we explored three fusion strategies for combining the outputs from the OCR model based on multiple super-resolved images. Notably, applying the Majority Vote by Character Position (MVCP) strategy with five super-resolved images improved the recognition rate from 31.1% to 44.7%. The proposed dataset enables the exploration of temporal relationships among low-resolution LPs, as it includes multiple sequential LR images for each LP. </li> -->
	<li>We conducted benchmark experiments on the proposed dataset using five state-of-the-art super-resolution models: (i) general-purpose approaches (SR3 <a href="https://ieeexplore.ieee.org/abstract/document/9887996" target="_blank">[Sahariaet al., 2023]</a>, Real-ESRGAN <a href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.html" target="_blank">[Wang et al., 2021]</a>), and (ii) LP-specialized networks (LPSRGAN <a href="https://www.sciencedirect.com/science/article/pii/S0925231224001978" target="_blank">[Pan et al., 2024]</a>, PLNET <a href="https://raysonlaroca.github.io/papers/nascimento2023super.pdf" target="_blank">[Nascimento et al., 2024a]</a>, and LCDNet <a href="https://raysonlaroca.github.io/papers/nascimento2024enhancing.pdf" target="_blank">[Nascimento et al., 2024b]</a>). For each track, we generated five super-resolved images from the LR images and compared the recognition results obtained by the leading Optical Character Recognition (OCR) model, GP_LPR [Liu et al., 2024b]. The super-resolution process significantly boosted recognition accuracy, increasing from 2.2% to 29.9% for a single super-resolved image. To further enhance LPR performance, we explored three fusion strategies for combining the outputs from the OCR model based on multiple super-resolved images. Notably, applying the Majority Vote by Character Position (MVCP) strategy with five super-resolved images improved the recognition rate from 29.9% to 42.3%. The proposed dataset enables the exploration of temporal relationships among low-resolution LPs, as it includes multiple sequential LR images for each LP. </li>
    </ul>
    <table class="table">
    <tr>
        <td><span><a href="https://valfride.github.io/nascimento2024toward/under_review.html" target="_blank">[arXiv]</a></span></td>
        <td><span><a href="https://raysonlaroca.github.io/bibtex/nascimento2025toward.txt" target="_blank">[BibTeX]</a></span></td>
        <td><span><a href="https://valfride.github.io/nascimento2024toward/under_review.html" target="_blank">[UFPR-SR-Plates]</a></span></td>
    </tr>
</table>
</div>

<h2><center>How to Access the Dataset</center></h2>
<div class="paper">
    <p>The UFPR-SR-Plates dataset is available for academic research purposes and is free to researchers affiliated with educational or research institutions for non-commercial use. To request access, carefully review and complete the license agreement, then send it to Professor David Menotti (<a href="mailto:menotti@inf.ufpr.br" target="_blank">menotti@inf.ufpr.br</a>). Please ensure the email is sent from a valid university domain (e.g., .edu, .ac, or similar). A download link will typically be provided within 1-5 business days. Incomplete requests or failure to follow the instructions may result in no response.</p>
</table>
</div>

<h2>Acknowledgements</h2>
<div class="paper">
    <p>This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001, and in part by the Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq)(# 315409/2023-1 and # 312565/2023-2). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Quadro RTX 8000 GPU used for this research.</p>
</div>

</body>
</html>
