<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Toward Advancing License Plate Super-Resolution in Real-World Scenarios: A Dataset and Benchmark</title>
<style>
    body {
        font-family: 'Arial', sans-serif;
        line-height: 1.6;
        margin: 0 auto;
        padding: 30px 20px;
        max-width: 1000px;
        color: #333;
    }

    .title {
        font-size: 34px;
        text-align: center;
        margin: 20px auto 30px;
        line-height: 1.3;
        color: #222;
        font-weight: 600;
    }

    .authors-table {
        margin: 20px auto;
        border-collapse: separate;
        border-spacing: 15px 5px;
    }

    .authors-table td {
        text-align: center;
        padding: 8px 12px;
        background: #f8f9fa;
        border-radius: 4px;
        transition: all 0.2s ease;
    }

    .authors-table a {
        color: #1a73e8;
        font-weight: 500;
    }

    .affiliations {
        margin: 20px auto;
        text-align: center;
        color: #666;
        font-size: 15px;
        line-height: 1.5;
    }

    figure {
        margin: 30px auto;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        border-radius: 4px;
        overflow: hidden;
    }

    figcaption {
        padding: 15px;
        font-size: 14px;
        color: #444;
        line-height: 1.5;
        background: #fff;
    }

    h2 {
        font-size: 24px;
        margin: 40px 0 20px;
        padding-bottom: 8px;
        border-bottom: 2px solid #1a73e8;
        text-align: center;
    }

    .card {
        background: #fff;
        border-radius: 8px;
        padding: 25px;
        margin: 20px 0;
        box-shadow: 0 2px 6px rgba(0,0,0,0.08);
        border: 1px solid #eee;
    }

    .links-container {
        display: flex;
        gap: 15px;
        margin: 20px 0;
        flex-wrap: wrap;
        justify-content: center;
    }

    .links-container a {
        padding: 8px 15px;
        background: #f8f9fa;
        border-radius: 4px;
        border: 1px solid #ddd;
        transition: all 0.2s ease;
    }

    a:hover {
        color: #1557b0;
        text-decoration: underline;
    }

    .authors-table td:hover {
        transform: translateY(-2px);
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }

    .links-container a:hover {
        background: #1a73e8;
        color: white;
        text-decoration: none;
        border-color: transparent;
    }

    ul {
        padding-left: 25px;
        margin: 15px 0;
    }

    li {
        margin-bottom: 12px;
        line-height: 1.5;
    }

    img {
        max-width: 100%;
        height: auto;
        display: block;
    }
</style>
</head>

<body>
<h1 class="title">Toward Advancing License Plate Super-Resolution<br>in Real-World Scenarios: A Dataset and Benchmark</h1>

<table class="authors-table">
    <tr>
        <td><a href="https://www.inf.ufpr.br/vwnascimento/" target="_blank">Valfride Nascimento</a><sup>1</sup></td>
        <td><a href="https://www.inf.ufpr.br/gelima/" target="_blank">Gabriel E. Lima</a><sup>1</sup></td>
        <td><a href="https://research.aston.ac.uk/en/persons/rafael-oliveira-ribeiro" target="_blank">Rafael O. Ribeiro</a><sup>2</sup></td>
        <td><a href="http://william.dcc.ufmg.br/" target="_blank">William Robson Schwartz</a><sup>3</sup></td>
        <td><a href="https://raysonlaroca.github.io/" target="_blank">Rayson Laroca</a><sup>1,4</sup></td>
        <td><a href="https://web.inf.ufpr.br/menotti/" target="_blank">David Menotti</a><sup>1</sup></td>
    </tr>
</table>

<div class="affiliations">
    <sup>1</sup>Federal University of Paraná<br>
    <sup>2</sup>Brazilian Federal Police<br>
    <sup>3</sup>Federal University of Minas Gerais<br>
    <sup>4</sup>Pontifical Catholic University of Paraná
</div>

<figure>
    <img src="carssrplates1.png" alt="Dataset examples">
    <figcaption>
    Examples of tracks from the UFPR-SR-Plates dataset. Each track comprises five consecutive LR images and five consecutive HR images of the same LP, captured under varying conditions. Each row shows a single track, with the LR images displayed on the left and the corresponding HR images on the right. We remark that even what we consider 'HR' in the context of this work is of lower quality than the datasets typically used in LPR research.
    </figcaption>
</figure>

<h2>Abstract</h2>
<div class="card">
    <p>Recent advancements in super-resolution for License Plate Recognition (LPR) have sought to address challenges posed by low-resolution (LR) and degraded images in surveillance, traffic monitoring, and forensic applications. However, existing studies have relied on private datasets and simplistic degradation models. To address this gap, we introduce UFPR-SR-Plates, a novel dataset containing 10,000 tracks with 100,000 paired low and high-resolution license plate images captured under real-world conditions. We establish a benchmark using multiple sequential LR and high-resolution (HR) images per vehicle – five of each – and two state-of-the-art models for super-resolution of license plates. We also investigate three fusion strategies to evaluate how combining predictions from a leading Optical Character Recognition (OCR) model for multiple super-resolved license plates enhances overall performance. Our findings demonstrate that super-resolution significantly boosts LPR performance, with further improvements observed when applying majority vote-based fusion techniques. Specifically, the Layout-Aware and Character-Driven Network (LCDNet) model combined with the Majority Vote by Character Position (MVCP) strategy led to the highest recognition rates, increasing from 1.7% with low-resolution images to 31.1% with super-resolution, and up to 44.7% when combining OCR outputs from five super-resolved images. These findings underscore the critical role of super-resolution and temporal information in enhancing LPR accuracy under real-world, adverse conditions. The proposed dataset is publicly available to support further research.</p>
</div>

<h2>Paper</h2>
<div class="card">
    <p><strong>Authors:</strong> Valfride Nascimento, Gabriel E. Lima, Rafael O. Ribeiro, William Robson Schwartz, Rayson Laroca, David Menotti</p>
    <p><strong>Title:</strong> Toward Advancing License Plate Super-Resolution in Real-World Scenarios: A Dataset and Benchmark</p>
    
    <p><strong>Summary:</strong></p>
    <p>In summary, the main contributions of this work are:</p>
    <ul>
        <li>A publicly available dataset containing 100,000 images, divided into 10,000 tracks, with each track containing five LR images and five HR images of the same LP. To enhance variability, 5,000 tracks were collected at a resolution of 1280 × 960 pixels, while the remaining 5,000 tracks were captured at 1920 × 1080 pixels. The dataset is evenly distributed between Mercosur and Brazilian LPs, making it the largest dataset in terms of the number of LPs for both layouts;</li>
        <li>We conducted benchmark experiments on the proposed dataset using five state-of-the-art super-resolution models: (i) general-purpose approaches (SR3 <a href="https://ieeexplore.ieee.org/abstract/document/9887996" target="_blank">[Sahariaet al., 2023]</a>, Real-ESRGAN <a href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.html" target="_blank">[Wang et al., 2021]</a>), and (ii) LP-specialized networks (LPSRGAN <a href="https://www.sciencedirect.com/science/article/pii/S0925231224001978" target="_blank">[Pan et al., 2024]</a>, PLNET <a href="https://raysonlaroca.github.io/papers/nascimento2023super.pdf" target="_blank">[Nascimento et al., 2024a]</a>, and LCDNet <a href="https://raysonlaroca.github.io/papers/nascimento2024enhancing.pdf" target="_blank">[Nascimento et al., 2024b]</a>). For each track, we generated five super-resolved images from the LR images and compared the recognition results obtained by the leading Optical Character Recognition (OCR) model, GP_LPR [Liu et al., 2024b]. The super-resolution process significantly boosted recognition accuracy, increasing from 2.2% to 29.9% for a single super-resolved image. To further enhance LPR performance, we explored three fusion strategies for combining the outputs from the OCR model based on multiple super-resolved images. Notably, applying the Majority Vote by Character Position (MVCP) strategy with five super-resolved images improved the recognition rate from 29.9% to 42.3%. The proposed dataset enables the exploration of temporal relationships among low-resolution LPs, as it includes multiple sequential LR images for each LP.</li>
    </ul>
    
    <div class="links-container">
        <a href="https://valfride.github.io/nascimento2024toward/under_review.html" target="_blank">[arXiv]</a>
        <a href="https://raysonlaroca.github.io/bibtex/nascimento2025toward.txt" target="_blank">[BibTeX]</a>
        <a href="https://valfride.github.io/nascimento2024toward/under_review.html" target="_blank">[UFPR-SR-Plates]</a>
    </div>
</div>

<h2>How to Access the Dataset</h2>
<div class="card">
    <p>The UFPR-SR-Plates dataset is available for academic research purposes and is free to researchers affiliated with educational or research institutions for non-commercial use. To request access, carefully review and complete the license agreement, then send it to Professor David Menotti (<a href="mailto:menotti@inf.ufpr.br" target="_blank">menotti@inf.ufpr.br</a>). Please ensure the email is sent from a valid university domain (e.g., .edu, .ac, or similar). A download link will typically be provided within 1-5 business days. Incomplete requests or failure to follow the instructions may result in no response.</p>
</div>

<h2>Acknowledgements</h2>
<div class="card">
    <p>This study was financed in part by the Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Finance Code 001, and in part by the Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq)(# 315409/2023-1 and # 312565/2023-2). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Quadro RTX 8000 GPU used for this research.</p>
</div>

</body>
</html>